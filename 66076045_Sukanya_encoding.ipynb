{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment:\n",
        "\n",
        "Write functions for the following text encoding.\n",
        "\n",
        "1. Index-based encoding\n",
        "\n",
        "2. Onehot encoding\n",
        "\n",
        "3. Bag-of-word encoding\n",
        "\n",
        "4. TF-IDF encoding\n",
        "\n",
        "5. Reduced Co-occurrence matrix (with window-size and reduced k-dimension parameters)\n",
        "\n",
        "Example: input_text = [\"all that glitters is not gold\"]\n",
        "                      [\"one for all and all for one\"]"
      ],
      "metadata": {
        "id": "J6qrsURjCYgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text):\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "# Example usage\n",
        "text1 = \"all that glitters is not gold\"\n",
        "text2 = \"one for all and all for one\"\n",
        "tokens1 = simple_tokenize(text1)\n",
        "tokens2 = simple_tokenize(text2)\n",
        "# Print the result\n",
        "print(\"Tokens for text 1:\", tokens1)\n",
        "print(\"Tokens for text 2:\", tokens2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MdKwveec2Q3",
        "outputId": "f245749c-39ea-4404-d15e-764e0f894eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens for text 1: ['all', 'that', 'glitters', 'is', 'not', 'gold']\n",
            "Tokens for text 2: ['one', 'for', 'all', 'and', 'all', 'for', 'one']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Index-based encoding"
      ],
      "metadata": {
        "id": "KKlBi59KehKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text):\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "def index_encoding(input_text):\n",
        "    # Create a vocabulary of unique words in the entire input_text\n",
        "    vocabulary = set(word for tokens in input_text for word in tokens)\n",
        "    # Create a dictionary to map each word to its index\n",
        "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "    # Create index-based encodings for each string in the input_text\n",
        "    index_encodings = []\n",
        "    for tokens in input_text:\n",
        "        encoding = [word_to_index[word] for word in tokens]\n",
        "        index_encodings.append(encoding)\n",
        "    return index_encodings, word_to_index"
      ],
      "metadata": {
        "id": "1HZmuALRa3KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text1 = \"all that glitters is not gold\"\n",
        "text2 = \"one for all and all for one\"\n",
        "tokens1 = simple_tokenize(text1)\n",
        "tokens2 = simple_tokenize(text2)\n",
        "index_encodings, vocabulary = index_encoding([tokens1, tokens2])\n",
        "# Print the result\n",
        "for i, encoding in enumerate(index_encodings):\n",
        "    print(f\"Index-based encoding for string {i+1}: {encoding}\")\n",
        "# Print the vocabulary\n",
        "\"Vocabulary:\", vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHloZeDsa5xh",
        "outputId": "3182c7b8-2d2f-41fc-ed67-637291a7b50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index-based encoding for string 1: [3, 4, 6, 2, 8, 7]\n",
            "Index-based encoding for string 2: [1, 5, 3, 0, 3, 5, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Vocabulary:',\n",
              " {'and': 0,\n",
              "  'one': 1,\n",
              "  'is': 2,\n",
              "  'all': 3,\n",
              "  'that': 4,\n",
              "  'for': 5,\n",
              "  'glitters': 6,\n",
              "  'gold': 7,\n",
              "  'not': 8})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Onehot encoding"
      ],
      "metadata": {
        "id": "2yus-ixTmYbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_enc(input_text):\n",
        "\n",
        "  # สร้างลิสต์ของคำทั้งหมดในข้อความ\n",
        "  all_words = ' '.join(input_text).split()\n",
        "\n",
        "# ข้อความตัวอย่าง\n",
        "text1 = \"all that glitters is not gold\"\n",
        "text2 = \"one for all and all for one\"\n",
        "\n",
        "# สร้างลิสต์ของคำทั้งหมด\n",
        "words = (text1 + \" \" + text2).split()\n",
        "\n",
        "# สร้างดิกชันนารีเพื่อกำหนด index ให้แต่ละคำ\n",
        "word_to_index = {word: idx for idx, word in enumerate(set(words))}\n",
        "\n",
        "# สร้างเวกเตอร์ One-hot Encoding\n",
        "one_hot_vectors = {word: [1 if i == word_to_index[word] else 0 for i in range(len(word_to_index))] for word in word_to_index}\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "for word, vector in one_hot_vectors.items():\n",
        "    print(f\"{word}: {vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwmn4XqJwBZW",
        "outputId": "c62495ff-c121-4c7a-8e28-d8563cd40ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "one: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "is: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "all: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "that: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "for: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "glitters: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "gold: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "not: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Bag-of-word encoding"
      ],
      "metadata": {
        "id": "FHLAn2XUMly6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def bow_encoding(input_text):\n",
        "    # Use CountVectorizer to create Bag-of-Words Encoding\n",
        "    vectorizer = CountVectorizer()\n",
        "    bow_encoding = vectorizer.fit_transform(input_text)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_bow = pd.DataFrame(bow_encoding.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Add a column with the original sentences\n",
        "    df_bow.insert(0, 'Sentences', input_text)\n",
        "\n",
        "    return df_bow\n",
        "\n",
        "# Example\n",
        "input_text = [\"all that glitters is not gold\", \"one for all and all for one\"]\n",
        "result = bow_encoding(input_text)\n",
        "\n",
        "# Display the result\n",
        "print(result.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAsRm-1zkLKg",
        "outputId": "4dcdd3cf-1673-4170-bf37-00f0d0165916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Sentences  all  and  for  glitters  gold  is  not  one  that\n",
            "all that glitters is not gold    1    0    0         1     1   1    1    0     1\n",
            "  one for all and all for one    2    1    2         0     0   0    0    2     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. TF-IDF encoding"
      ],
      "metadata": {
        "id": "d0SmOYERNUQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_encoding(input_text):\n",
        "    # Use TfidfVectorizer to create TF-IDF Encoding\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_encoding = vectorizer.fit_transform(input_text)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_tfidf = pd.DataFrame(tfidf_encoding.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Add a column with the original sentences\n",
        "    df_tfidf.insert(0, 'Sentences', input_text)\n",
        "\n",
        "    return df_tfidf"
      ],
      "metadata": {
        "id": "tOR-KTAJk4tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "input_text = [ \"all that glitters is not gold\", \"one for all and all for one\"]\n",
        "result = tfidf_encoding(input_text)\n",
        "\n",
        "# Display the result\n",
        "print(result.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gg1kFUuk7D_",
        "outputId": "39c75427-5e2c-4118-82f3-9944336cd350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Sentences      all     and      for  glitters    gold      is     not      one    that\n",
            "all that glitters is not gold 0.303216 0.00000 0.000000   0.42616 0.42616 0.42616 0.42616 0.000000 0.42616\n",
            "  one for all and all for one 0.428569 0.30117 0.602339   0.00000 0.00000 0.00000 0.00000 0.602339 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Co-occurrence matrix"
      ],
      "metadata": {
        "id": "NbFg5psGNxHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduced Co-occurrence Matrix\n",
        "\n",
        "ฟังก์ชัน co_occurrence_matrix จะทำการสร้าง Co-occurrence Matrix ที่ลดรูป (Reduced) โดยให้พารามิเตอร์ window_size กำหนดขนาดของหน้าต่าง (window) และ k_dimension กำหนดมิติที่จะลดลงมา."
      ],
      "metadata": {
        "id": "4X68Fa9ANtZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def co_occurrence_matrix(input_text, window_size=1, k_dimension=2):\n",
        "    # Tokenize input_text\n",
        "    tokens = [sentence.split() for sentence in input_text]\n",
        "\n",
        "    # Create vocabulary\n",
        "    vocabulary = list(set([word for sentence in tokens for word in sentence]))\n",
        "\n",
        "    # Create coo_dict for co-occurrence matrix\n",
        "    coo_dict = {word: {other_word: 0 for other_word in vocabulary} for word in vocabulary}\n",
        "\n",
        "    # Update coo_dict based on co-occurrence counts\n",
        "    for sentence in tokens:\n",
        "        for i, word1 in enumerate(sentence):\n",
        "            for j, word2 in enumerate(sentence[max(0, i - window_size):i + window_size + 1]):\n",
        "                if i != j:\n",
        "                    coo_dict[word1][word2] += 1\n",
        "\n",
        "    # Convert coo_dict to DataFrame\n",
        "    df_cooc = pd.DataFrame(coo_dict).T.astype('int')\n",
        "\n",
        "    return df_cooc\n",
        "\n",
        "# Example\n",
        "input_text = [\"all that glitters is not gold\", \"one for all and all for one\"]\n",
        "result = co_occurrence_matrix(input_text, window_size=2, k_dimension=3)\n",
        "\n",
        "# Display the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC0ZHlcBn9vd",
        "outputId": "2d934d6a-05a1-4e50-a9ac-81570ed92c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          and  one  is  all  that  for  glitters  gold  not\n",
            "and         1    0   0    1     0    2         0     0    0\n",
            "one         0    1   0    2     0    2         0     0    0\n",
            "is          0    0   1    0     1    0         1     1    0\n",
            "all         2    1   0    3     1    2         1     0    0\n",
            "that        0    0   1    1     0    0         1     0    0\n",
            "for         2    2   0    2     0    1         0     0    0\n",
            "glitters    0    0   1    1     1    0         0     0    1\n",
            "gold        0    0   1    0     0    0         0     1    1\n",
            "not         0    0   1    0     0    0         1     1    1\n"
          ]
        }
      ]
    }
  ]
}